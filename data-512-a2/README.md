# DATA 512: Human Centered Data Science - A2: Bias in data

The goal of this repository is to identify potential bias in multiple datasets of hostile speech used by Wikimedia Research and Jigsaw for research and describe implications of those biases.

## Datasets
The data that I focus on contains online discussion posts made by Wikipedia editors. Crowdworkers labelled these posts for three kinds of hostile speech: “toxicity”, “aggression”, and “personal attacks”. <br />
The datasets that I analyzed include information about the discussion posts, crowdworkers labels on those posts, and crowdworkers' demographics.  <br />
They are accessiable [here](https://figshare.com/projects/Wikipedia_Talk/16731).

## Background
Google data scientists used these annotated datasets to train machine learning models as part of a project called Conversation AI. The models have been used in a variety of software products and made freely accessible to anyone through the Perspective API.   <br />
An overview of the research project is [here](https://meta.wikimedia.org/wiki/Research:Detox).   <br />
The github page for the Perspective API is available [here](https://github.com/conversationai/perspectiveapi/blob/master/2-api/methods.md).


## License
Source data is available under the [MIT Licence](LICENSE).



